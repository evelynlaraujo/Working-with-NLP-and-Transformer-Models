{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1488c85",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Project 5: Goals and Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d8c13",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "The goals of this assignment are:\n",
    "* To work with the object oriented version of our corpus code.\n",
    "* To modify a web app that we can use to analyze text data.\n",
    "* To finetune a transformer model and write a model card for it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Copy your `spacy_on_corpus.py` from project 4b.\n",
    "2. Copy the anvil callable functions from project 4b into the file `server.py`.\n",
    "3. Run % `pip install -r requirements.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Sure We Can Work With .py Files We Are Editing\n",
    "\n",
    "Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a Corpus\n",
    "\n",
    "In the code cell below, build a corpus using `creator.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy_on_corpus import corpus\n",
    "my_corpus=corpus.build_corpus('creator.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune a Transformer Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can currently get document-level sentiment but quite often a movie review is nuanced: some sentences say good things about some aspects of the movie, while others say bad things about other aspects. In this project, we will finetune a transformer model on the sentiment of sentences from movie reviews, and then add to our webapp the ability to see sentence-level sentiment for a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Some Labeled Data\n",
    "\n",
    "We are going to use the (SST)[https://huggingface.co/datasets/sst] dataset. Note the datasheet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Filter: 100%|██████████| 67349/67349 [00:00<00:00, 285185.17 examples/s]\n",
      "Filter: 100%|██████████| 872/872 [00:00<00:00, 169090.76 examples/s]\n",
      "Filter: 100%|██████████| 1821/1821 [00:00<00:00, 221797.76 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# datasets is a huggingface python package that makes it easy to download huggingface datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# download the sst dataset\n",
    "raw_sst = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "# make it smaller for testing; once everything is working, train on all the data by commenting this line out and rerunning the notebook\n",
    "raw_sst = raw_sst.filter(lambda e, i: i<300, with_indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we look at the dataset.\n",
    "\n",
    "**ALWAYS LOOK AT YOUR DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the sst dataset\n",
    "raw_sst\n",
    "# look at the sst training data\n",
    "raw_sst['train']\n",
    "# look at the sst training data sentences. Note each data point is a pre-tokenized sentence.\n",
    "raw_sst['train']['sentence']\n",
    "# look at the sst training data labels.\n",
    "raw_sst['train']['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the Data\n",
    "\n",
    "We will use the small `distilbert` model for this project. So we want to use its tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "#distilbert-basae-uncased for easy extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to tokenize our data using that tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 300/300 [00:00<00:00, 4270.71 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 6567.83 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 5831.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def transformer_tokenize(example):\n",
    "    \"\"\"Tokenizes the input data using the designated transformer tokenizer.\n",
    "\n",
    "    :param example: a text\n",
    "    :type example: str\n",
    "    \"\"\"\n",
    "    return tokenizer(example['sentence'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# this tokenizes the train, validation and test sets\n",
    "tokenized_sst = raw_sst.map(transformer_tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a Transformer Model\n",
    "\n",
    "We will use the distilbert model for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = 2\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-cased\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and Run a Trainer\n",
    "\n",
    "Huggingface gives us a nice clean way to train: the `Trainer`. Each trainer has training arguments - where you can set hyperparameters. We will make a default set of training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"sst_model\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add an accuracy metric from the `evaluate` package so we can see accuracy while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this huggingf\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Setup evaluation \n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute the metric!\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will make a trainer using the model, the training arguments, our train and our dev data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=tokenized_sst[\"train\"], eval_dataset=tokenized_sst[\"validation\"], compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we train.\n",
    "\n",
    "**This step takes a long time.** If you want to speed it up, you will need a GPU! But codespaces don't currently have GPU options. So:\n",
    "\n",
    "1. Download this notebook.\n",
    "2. Open [https://colab.research.google.com](https://colab.research.google.com).\n",
    "3. Upload the notebook.\n",
    "4. Add a cell at the top of the notebook and in it type:\n",
    "```\n",
    "!pip install datasets\n",
    "!pip install transformers[torch]\n",
    "!pip install evaluate\n",
    "```\n",
    "4. In the Runtime menu, choose `GPU`.\n",
    "5. Run the notebook there to train a model.\n",
    "6. Download the trained model.\n",
    "   * in a code cell, type `!tar -czf model.tgz sst-model`\n",
    "   * download model.tgz\n",
    "7. Upload the trained model here in the codespace.\n",
    "   * upload model.tgz\n",
    "   * in the terminal, type `!tar -xzf model.tgz`\n",
    "\n",
    "After this course, you can always still use codespaces, and I recommend it because of the tight integration with Github (so your code is saved!). You can *also* always use Colab. If you use Colab, your notebooks will be backed up in your Google Drive, but *no other files that you generated in colab are saved*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 19:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.648087</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.736938</td>\n",
       "      <td>0.673333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.744241</td>\n",
       "      <td>0.736667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=114, training_loss=0.37935069569370206, metrics={'train_runtime': 1182.8896, 'train_samples_per_second': 0.761, 'train_steps_per_second': 0.096, 'total_flos': 119220658790400.0, 'train_loss': 0.37935069569370206, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"sst-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "Now we should evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentence_sentiment = pipeline(\"text-classification\", model=\"sst-model\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we try the model on a couple of sample sentences to sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9938607215881348}]\n",
      "[{'label': 'LABEL_1', 'score': 0.9945043325424194}]\n"
     ]
    }
   ],
   "source": [
    "print(sentence_sentiment(\"This movie was awful!\"))\n",
    "\n",
    "print(sentence_sentiment(\"This movie was great!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to run the model on each of our test data points.\n",
    "\n",
    "Notice that the model outputs 'LABEL_0' or 'LABEL_1' while the data has labels 0 and 1. So *you* should define a function to map the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(output):\n",
    "    \"\"\"Gets a numeric label for the output from the classifier.\n",
    "        Sample output from classifier:  [{'label': 'LABEL_0', 'score': 0.61}] corresponds to label 0\n",
    "        Sample output from classifier: [{'label': 'LABEL_1', 'score': 0.72}] corresponds to label 1  \n",
    "\n",
    "        :param output: the output from the classifier\n",
    "        :type output: list[dict]\n",
    "        :returns: a label\n",
    "        :rtype: int\n",
    "    \"\"\"\n",
    "    ### other option\n",
    "    #if output['label] =='LABEL_0':\n",
    "    #   return 0\n",
    "    #else:\n",
    "    #   return 1\n",
    "    true_labels={'LABEL_0': 0, 'LABEL_1':1}\n",
    "    return true_labels[output[0]['label']]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the classifier on each dev data point.\n",
    "\n",
    "Each element in `raw_sst['validation']` is a dictionary with keys `idx`, `sentence` and `label`. For each dev data point, you should make a new dictionary with keys `idx`, `sentence`, `label` and `pred` (for the output from the classifier). Add this dictionary to the list of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "# your work here!\n",
    "for datum in raw_sst['validation']:\n",
    "    output=sentence_sentiment(datum['sentence'])\n",
    "    results.append({'idx':datum['idx'], 'sentence': datum['sentence'], 'label':datum['label'], 'pred': get_label(output)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'idx': 0,\n",
       "  'sentence': \"it 's a charming and often affecting journey . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 1,\n",
       "  'sentence': 'unflinchingly bleak and desperate ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 2,\n",
       "  'sentence': 'allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 3,\n",
       "  'sentence': \"the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 4,\n",
       "  'sentence': \"it 's slow -- very , very slow . \",\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 5,\n",
       "  'sentence': 'although laced with humor and a few fanciful touches , the film is a refreshingly serious look at young women . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 6, 'sentence': 'a sometimes tedious film . ', 'label': 0, 'pred': 0},\n",
       " {'idx': 7,\n",
       "  'sentence': \"or doing last year 's taxes with your ex-wife . \",\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 8,\n",
       "  'sentence': \"you do n't have to know about music to appreciate the film 's easygoing blend of comedy and romance . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 9,\n",
       "  'sentence': \"in exactly 89 minutes , most of which passed as slowly as if i 'd been sitting naked on an igloo , formula 51 sank from quirky to jerky to utter turkey . \",\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 10,\n",
       "  'sentence': 'the mesmerizing performances of the leads keep the film grounded and keep the audience riveted . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 11,\n",
       "  'sentence': 'it takes a strange kind of laziness to waste the talents of robert forster , anne meara , eugene levy , and reginald veljohnson all in the same movie . ',\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 12,\n",
       "  'sentence': '... the film suffers from a lack of humor ( something needed to balance out the violence ) ... ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 13,\n",
       "  'sentence': \"we root for ( clara and paul ) , even like them , though perhaps it 's an emotion closer to pity . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 14,\n",
       "  'sentence': \"even horror fans will most likely not find what they 're seeking with trouble every day ; the movie lacks both thrills and humor . \",\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 15,\n",
       "  'sentence': 'a gorgeous , high-spirited musical from india that exquisitely blends music , dance , song , and high drama . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 16,\n",
       "  'sentence': \"the emotions are raw and will strike a nerve with anyone who 's ever had family trauma . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 17,\n",
       "  'sentence': \"audrey tatou has a knack for picking roles that magnify her outrageous charm , and in this literate french comedy , she 's as morning-glory exuberant as she was in amélie . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 18,\n",
       "  'sentence': '... the movie is just a plain old monster . ',\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 19,\n",
       "  'sentence': 'in its best moments , resembles a bad high school production of grease , without benefit of song . ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 20,\n",
       "  'sentence': 'pumpkin takes an admirable look at the hypocrisy of political correctness , but it does so with such an uneven tone that you never know when humor ends and tragedy begins . ',\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 21,\n",
       "  'sentence': 'the iditarod lasts for days - this just felt like it did . ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 22,\n",
       "  'sentence': 'holden caulfield did it better . ',\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 23,\n",
       "  'sentence': 'a delectable and intriguing thriller filled with surprises , read my lips is an original . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 24,\n",
       "  'sentence': 'seldom has a movie so closely matched the spirit of a man and his work . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 25,\n",
       "  'sentence': \"nicks , seemingly uncertain what 's going to make people laugh , runs the gamut from stale parody to raunchy sex gags to formula romantic comedy . \",\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 26,\n",
       "  'sentence': 'the action switches between past and present , but the material link is too tenuous to anchor the emotional connections that purport to span a 125-year divide . ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 27,\n",
       "  'sentence': \"it 's an offbeat treat that pokes fun at the democratic exercise while also examining its significance for those who take part . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 28,\n",
       "  'sentence': \"it 's a cookie-cutter movie , a cut-and-paste job . \",\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 29,\n",
       "  'sentence': 'i had to look away - this was god awful . ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 30,\n",
       "  'sentence': \"thanks to scott 's charismatic roger and eisenberg 's sweet nephew , roger dodger is one of the most compelling variations on in the company of men . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 31,\n",
       "  'sentence': \"... designed to provide a mix of smiles and tears , `` crossroads '' instead provokes a handful of unintentional howlers and numerous yawns . \",\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 32,\n",
       "  'sentence': 'a gorgeous , witty , seductive movie . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 33,\n",
       "  'sentence': \"if the movie succeeds in instilling a wary sense of ` there but for the grace of god , ' it is far too self-conscious to draw you deeply into its world . \",\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 34,\n",
       "  'sentence': \"it does n't believe in itself , it has no sense of humor ... it 's just plain bored . \",\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 35,\n",
       "  'sentence': \"a sequence of ridiculous shoot - 'em - up scenes . \",\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 36,\n",
       "  'sentence': 'the weight of the piece , the unerring professionalism of the chilly production , and the fascination embedded in the lurid topic prove recommendation enough . ',\n",
       "  'label': 1,\n",
       "  'pred': 0},\n",
       " {'idx': 37,\n",
       "  'sentence': \"( w ) hile long on amiable monkeys and worthy environmentalism , jane goodall 's wild chimpanzees is short on the thrills the oversize medium demands . \",\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 38,\n",
       "  'sentence': 'as surreal as a dream and as detailed as a photograph , as visually dexterous as it is at times imaginatively overwhelming . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 39,\n",
       "  'sentence': 'escaping the studio , piccoli is warmly affecting and so is this adroitly minimalist movie . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 40,\n",
       "  'sentence': \"there 's ... tremendous energy from the cast , a sense of playfulness and excitement that seems appropriate . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 41,\n",
       "  'sentence': 'this illuminating documentary transcends our preconceived vision of the holy land and its inhabitants , revealing the human complexities beneath . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 42,\n",
       "  'sentence': \"the subtle strength of `` elling '' is that it never loses touch with the reality of the grim situation . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 43,\n",
       "  'sentence': 'holm ... embodies the character with an effortlessly regal charisma . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 44,\n",
       "  'sentence': 'the title not only describes its main characters , but the lazy people behind the camera as well . ',\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 45,\n",
       "  'sentence': 'it offers little beyond the momentary joys of pretty and weightless intellectual entertainment . ',\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 46,\n",
       "  'sentence': 'a synthesis of cliches and absurdities that seems positively decadent in its cinematic flash and emptiness . ',\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 47,\n",
       "  'sentence': 'a subtle and well-crafted ( for the most part ) chiller . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 48,\n",
       "  'sentence': 'has a lot of the virtues of eastwood at his best . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 49,\n",
       "  'sentence': \"it 's hampered by a lifetime-channel kind of plot and a lead actress who is out of her depth . \",\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 50,\n",
       "  'sentence': 'it feels like an after-school special gussied up with some fancy special effects , and watching its rote plot points connect is about as exciting as gazing at an egg timer for 93 minutes . ',\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 51,\n",
       "  'sentence': \"for the most part , director anne-sophie birot 's first feature is a sensitive , extraordinarily well-acted drama . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 52,\n",
       "  'sentence': 'mr. tsai is a very original artist in his medium , and what time is it there ? ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 53,\n",
       "  'sentence': 'sade is an engaging look at the controversial eponymous and fiercely atheistic hero . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 54,\n",
       "  'sentence': 'so devoid of any kind of intelligible story that it makes films like xxx and collateral damage seem like thoughtful treatises ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 55,\n",
       "  'sentence': 'a tender , heartfelt family drama . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 56,\n",
       "  'sentence': '... a hollow joke told by a cinematic gymnast having too much fun embellishing the misanthropic tale to actually engage it . ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 57,\n",
       "  'sentence': \"the cold turkey would 've been a far better title . \",\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 58,\n",
       "  'sentence': 'manages to be both repulsively sadistic and mundane . ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 59,\n",
       "  'sentence': \"it 's just disappointingly superficial -- a movie that has all the elements necessary to be a fascinating , involving character study , but never does more than scratch the surface . \",\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 60,\n",
       "  'sentence': \"this is a story of two misfits who do n't stand a chance alone , but together they are magnificent . \",\n",
       "  'label': 1,\n",
       "  'pred': 0},\n",
       " {'idx': 61,\n",
       "  'sentence': 'schaeffer has to find some hook on which to hang his persistently useless movies , and it might as well be the resuscitation of the middle-aged character . ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 62,\n",
       "  'sentence': 'the primitive force of this film seems to bubble up from the vast collective memory of the combatants . ',\n",
       "  'label': 1,\n",
       "  'pred': 0},\n",
       " {'idx': 63,\n",
       "  'sentence': 'on this tricky topic , tadpole is very much a step in the right direction , with its blend of frankness , civility and compassion . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 64,\n",
       "  'sentence': \"the script kicks in , and mr. hartley 's distended pace and foot-dragging rhythms follow . \",\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 65,\n",
       "  'sentence': \"you wonder why enough was n't just a music video rather than a full-length movie . \",\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 66,\n",
       "  'sentence': \"if you 're hard up for raunchy college humor , this is your ticket right here . \",\n",
       "  'label': 1,\n",
       "  'pred': 0},\n",
       " {'idx': 67,\n",
       "  'sentence': 'a fast , funny , highly enjoyable movie . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 68,\n",
       "  'sentence': 'good old-fashioned slash-and-hack is back ! ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 69,\n",
       "  'sentence': 'this one is definitely one to skip , even for horror movie fanatics . ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 70,\n",
       "  'sentence': 'for all its impressive craftsmanship , and despite an overbearing series of third-act crescendos , lily chou-chou never really builds up a head of emotional steam . ',\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 71,\n",
       "  'sentence': 'exquisitely nuanced in mood tics and dialogue , this chamber drama is superbly acted by the deeply appealing veteran bouquet and the chilling but quite human berling . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 72,\n",
       "  'sentence': 'uses high comedy to evoke surprising poignance . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 73,\n",
       "  'sentence': 'one of creepiest , scariest movies to come along in a long , long time , easily rivaling blair witch or the others . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 74,\n",
       "  'sentence': 'a string of rehashed sight gags based in insipid vulgarity . ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 75,\n",
       "  'sentence': \"among the year 's most intriguing explorations of alientation . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 76,\n",
       "  'sentence': 'the movie fails to live up to the sum of its parts . ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 77,\n",
       "  'sentence': \"the son 's room is a triumph of gentility that earns its moments of pathos . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 78,\n",
       "  'sentence': 'there is nothing outstanding about this film , but it is good enough and will likely be appreciated most by sailors and folks who know their way around a submarine . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 79,\n",
       "  'sentence': 'this is a train wreck of an action film -- a stupefying attempt by the filmmakers to force-feed james bond into the mindless xxx mold and throw 40 years of cinematic history down the toilet in favor of bright flashes and loud bangs . ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 80,\n",
       "  'sentence': \"the draw ( for `` big bad love '' ) is a solid performance by arliss howard . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 81,\n",
       "  'sentence': 'green might want to hang onto that ski mask , as robbery may be the only way to pay for his next project . ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 82,\n",
       "  'sentence': \"it 's one pussy-ass world when even killer-thrillers revolve around group therapy sessions . \",\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 83,\n",
       "  'sentence': \"though it 's become almost redundant to say so , major kudos go to leigh for actually casting people who look working-class . \",\n",
       "  'label': 1,\n",
       "  'pred': 0},\n",
       " {'idx': 84,\n",
       "  'sentence': \"the band 's courage in the face of official repression is inspiring , especially for aging hippies ( this one included ) . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 85,\n",
       "  'sentence': 'the movie achieves as great an impact by keeping these thoughts hidden as ... ( quills ) did by showing them . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 86,\n",
       "  'sentence': 'the film flat lines when it should peak and is more missed opportunity and trifle than dark , decadent truffle . ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 87,\n",
       "  'sentence': 'jaglom ... put ( s ) the audience in the privileged position of eavesdropping on his characters ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 88,\n",
       "  'sentence': \"fresnadillo 's dark and jolting images have a way of plying into your subconscious like the nightmare you had a week ago that wo n't go away . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 89,\n",
       "  'sentence': \"we know the plot 's a little crazy , but it held my interest from start to finish . \",\n",
       "  'label': 1,\n",
       "  'pred': 0},\n",
       " {'idx': 90,\n",
       "  'sentence': \"it 's a scattershot affair , but when it hits its mark it 's brilliant . \",\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 91,\n",
       "  'sentence': 'hardly a masterpiece , but it introduces viewers to a good charitable enterprise and some interesting real people . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 92,\n",
       "  'sentence': \"you wo n't like roger , but you will quickly recognize him . \",\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 93,\n",
       "  'sentence': \"if steven soderbergh 's ` solaris ' is a failure it is a glorious failure . \",\n",
       "  'label': 1,\n",
       "  'pred': 0},\n",
       " {'idx': 94,\n",
       "  'sentence': 'byler reveals his characters in a way that intrigues and even fascinates us , and he never reduces the situation to simple melodrama . ',\n",
       "  'label': 1,\n",
       "  'pred': 1},\n",
       " {'idx': 95,\n",
       "  'sentence': 'this riveting world war ii moral suspense story deals with the shadow side of american culture : racial prejudice in its ugly and diverse forms . ',\n",
       "  'label': 0,\n",
       "  'pred': 1},\n",
       " {'idx': 96,\n",
       "  'sentence': \"it 's difficult to imagine the process that produced such a script , but here 's guessing that spray cheese and underarm noises played a crucial role . \",\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 97,\n",
       "  'sentence': 'no sophomore slump for director sam mendes , who segues from oscar winner to oscar-winning potential with a smooth sleight of hand . ',\n",
       "  'label': 1,\n",
       "  'pred': 0},\n",
       " {'idx': 98,\n",
       "  'sentence': 'on the whole , the movie lacks wit , feeling and believability to compensate for its incessant coarseness and banality . ',\n",
       "  'label': 0,\n",
       "  'pred': 0},\n",
       " {'idx': 99,\n",
       "  'sentence': 'why make a documentary about these marginal historical figures ? ',\n",
       "  'label': 0,\n",
       "  'pred': 0}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have:\n",
    "\n",
    "* `gold` labels, and\n",
    "* model predictions\n",
    "\n",
    "for each of the dev data points.\n",
    "\n",
    "We will calculate two metrics:\n",
    "\n",
    "1. accuracy\n",
    "2. confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "In the code cell below, implement the `accuracy` function. The accuracy of a classifier is the number of correctly labeled data points divided by the total number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(results):\n",
    "    \"\"\" Returns the accuracy of a list of classifier results\n",
    "\n",
    "    :param results: a list of dictionaries. Each dictionary contains, at minimum, the keys 'label' and 'pred'\n",
    "    :type results: list[dict]\n",
    "    :returns: accuracy\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    accurate_data=0\n",
    "    for datum in results:\n",
    "        if datum['label']== datum['pred']:\n",
    "            accurate_data+=1\n",
    "    accuracy=accurate_data/len(results)  \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print the accuracy of the finetuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "In the code cell below, implement the `confusion_matrix` function. A confusion matrix for a classifier is like a spreadsheet or table that has all the labels along the rows and columns. Each cell contains the number of data points where the gold label corresponded to that row label, and the predicted label to that column label.\n",
    "\n",
    "For example, for labels `TRUE` and `FALSE`, here is a possible confusion matrix:\n",
    "\n",
    "| | TRUE | FALSE |\n",
    "| --- | ---- | ----- |\n",
    "| TRUE | 5 | 2   |\n",
    "| FALSE | 1 | 4   | \n",
    "\n",
    "This says that there were 7 total data points with gold label `TRUE`, of which 5 had predicted label `TRUE`. There were 5 total data points with gold label `FALSE`, of which 4 had predicted label `FALSE`. This is a pretty good classifier!\n",
    "\n",
    "Your confusion matrix will be a dictionary of dictionaries. Here's the above confusion matrix as a dictionary of dictionaries:\n",
    "```\n",
    "cf = {'TRUE': {'TRUE': 5, 'FALSE': 2}, 'FALSE': {'TRUE': 1, 'FALSE': 4}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(results):\n",
    "    \"\"\" Returns the confusion matrix for a list of classifier results\n",
    "\n",
    "    :param results: a list of dictionaries. Each dictionary contains, at minimum, the keys 'label' and 'pred'\n",
    "    :type results: list[dict]\n",
    "    :returns: confusion matrix\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    confusion={}\n",
    "    for datum in results:\n",
    "        if datum['label'] not in confusion:\n",
    "            confusion[datum['label']]={}\n",
    "        if datum['pred'] not in confusion[datum['label']]:\n",
    "            confusion[datum['label']][datum['pred']]=1\n",
    "        else:\n",
    "            confusion[datum['label']][datum['pred']]+=1\n",
    "    return confusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print the confusion matrix for the finetuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {1: 44, 0: 8}, 0: {0: 29, 1: 19}}\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Your Finetuned Model to Your Webapp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Create a class attribute in the `corpus` class for loading your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create an instance method, `get_sentence_level_sentiment`, in the `corpus` class. This method should return a list of pairs `(sentence, label)` where `label` \n",
    " is the sentiment label for the sentence. Test it in the code cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9952759742736816}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_sentiment(\"Hello my name is Evelyn, I am having a great day!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"It's a shame that the weak writing undermines The Creator so much, as there are some intriguing concepts that could have been compelling if executed better.\",\n",
       "  'NEGATIVE'),\n",
       " (\"For the most part, it's a mishmash of other movies with not much to say on its own.\",\n",
       "  'NEGATIVE')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy_on_corpus import corpus\n",
    "my_corpus.get_sentence_level_sentiment('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create an instance method, `render_document_sentiments`, in the `corpus` class. This method should return a markdown table for the document containing the sentences and their corresponding sentiment labels. At the bottom, it should have an extra row where the \"sentence\" is the string \"document\" and the label is the document-level sentiment (*not* from your finetuned model; from project 4b). Test it in the code cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Document Sentiments\\n| Sentence | Sentiment |\\n| -------- | ---------- |\\n| It's a shame that the weak writing undermines The Creator so much, as there are some intriguing concepts that could have been compelling if executed better. | NEGATIVE |\\n| For the most part, it's a mishmash of other movies with not much to say on its own. | NEGATIVE |\\n| Document | [{'label': 'NEGATIVE', 'score': 0.9997203946113586}] |\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_corpus.render_document_sentiments('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e9a4de",
   "metadata": {},
   "source": [
    "Document Sentiments\n",
    "| Sentence | Sentiment|\n",
    "| -------- | ---------- |\n",
    "| It's a shame that the weak writing undermines The Creator so much, as there are some intriguing concepts that could have been compelling if executed better. | NEGATIVE |\n",
    "| For the most part, it's a mishmash of other movies with not much to say on its own. | NEGATIVE |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. In `server.py`, add an anvil callable function, `get_doc_sentiment_markdown`, that calls `render_document_sentiments`. Test it in the code cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4512819e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Document Sentiments\\n| Sentence | Sentiment |\\n| -------- | ---------- |\\n| Although 'New Asia' is America's enemy, we are encouraged to transfer our sympathies in that direction. | POSITIVE |\\n| Yet the abiding vision of Asian life is a mass of touristic clichés seen through western eyes. | NEGATIVE |\\n| Document | [{'label': 'NEGATIVE', 'score': 0.9748802781105042}] |\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_corpus.render_document_sentiments('2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fa39c7",
   "metadata": {},
   "source": [
    "Document Sentiments\n",
    "| Sentence | Sentiment |\n",
    "| -------- | ---------- |\n",
    "| Although 'New Asia' is America's enemy, we are encouraged to transfer our sympathies in that direction. | POSITIVE |\n",
    "| Yet the abiding vision of Asian life is a mass of touristic clichés seen through western eyes. | NEGATIVE |\\n| Document | [{'label': 'NEGATIVE', 'score': 0.9748802781105042}] |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Document Sentiments\\n| Sentence | Sentiment |\\n| -------- | ---------- |\\n| Although 'New Asia' is America's enemy, we are encouraged to transfer our sympathies in that direction. | POSITIVE |\\n| Yet the abiding vision of Asian life is a mass of touristic clichés seen through western eyes. | NEGATIVE |\\n| Document | [{'label': 'NEGATIVE', 'score': 0.9748802781105042}] |\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import server\n",
    "server.get_doc_sentiment_markdown('2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05080fbd",
   "metadata": {},
   "source": [
    "| Sentence | Sentiment |\n",
    " -------- | ---------- |\n",
    "| Although 'New Asia' is America's enemy, we are encouraged to transfer our sympathies in that direction. | POSITIVE |\n",
    "| Yet the abiding vision of Asian life is a mass of touristic clichés seen through western eyes. | NEGATIVE |\n",
    "| Document | [{'label': 'NEGATIVE', 'score': 0.9748802781105042}] |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Card\n",
    "\n",
    "***ALWAYS DOCUMENT YOUR MODEL***\n",
    "\n",
    "Complete the model card reading in Perusall.\n",
    "\n",
    "Then, complete the model card in `model_card.md` for your finetuned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "* https://livingdatalab.com/posts/2023-04-23-fine-tuning-a-sentiment-analysis-model-with-huggingface.html\n",
    "* https://huggingface.co/docs/transformers/v4.15.0/model_sharing\n",
    "* https://huggingface.co/docs/datasets/process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
